"""Agent JSON → React components"""

import asyncio
import json
import uuid
from contextlib import asynccontextmanager
from pathlib import Path
from threading import Thread
from typing import AsyncGenerator, Dict, List, Optional

from .logger import logger


def _load_registry() -> Dict[str, Dict[str, str]]:
    """Load component registry"""
    registry_paths = [
        Path(__file__).parent.parent.parent.parent / "ai.json",
        Path.cwd() / "ai.json",
        Path(__file__).parent / "ai-registry.json",
    ]

    for registry_path in registry_paths:
        if registry_path.exists():
            try:
                data = json.loads(registry_path.read_text())
                components = data.get("components", {})
                if components:
                    return components
            except Exception:
                continue

    return {}


def protocol(components: Optional[List[str]] = None) -> str:
    """LLM format instructions"""
    if not components:
        # Built-in component types
        components = [
            "card",
            "timeline",
            "accordion",
            "code",
            "gallery",
            "reference",
            "suggestions",
            "table",
            "tabs",
            "tree",
            "markdown",
        ]
    elif "markdown" not in components:
        # Always ensure markdown fallback
        components = components + ["markdown"]

    return f"Available components: {', '.join(sorted(components))}\n\nSupports arrays for composition: [comp1, [comp2, comp3], comp4] = vertical stack with horizontal row"


async def shape(response: str, context: dict = None, llm=None) -> str:
    """Transform text → components"""
    if not llm:
        from .llms import llm as create_llm

        llm = create_llm()
    from .shaper import shape

    return await shape(response, context, llm)


class CallbackServer:
    """Isolated callback server for agent interactions"""

    def __init__(self, port: int = 8228):
        self.port = port
        self.callbacks: Dict[str, asyncio.Future] = {}
        self._server_started = False

    def start_server(self):
        """Start callback server if not already running"""
        if self._server_started:
            return

        try:
            import uvicorn
            from fastapi import FastAPI
            from fastapi.middleware.cors import CORSMiddleware
        except ImportError:
            raise ImportError("pip install fastapi uvicorn for ai() function") from None

        app = FastAPI()
        app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"])

        @app.post("/callback/{callback_id}")
        async def handle_callback(callback_id: str, request: dict):
            if callback_id in self.callbacks and not self.callbacks[callback_id].done():
                self.callbacks[callback_id].set_result(
                    {"action": request.get("action"), "data": request.get("data")}
                )
            return {"status": "continued"}

        def run_server():
            uvicorn.run(app, host="0.0.0.0", port=self.port, log_level="critical")

        Thread(target=run_server, daemon=True).start()
        self._server_started = True

    @asynccontextmanager
    async def callback_context(self, callback_id: str):
        """Context manager for isolated callback handling"""
        self.callbacks[callback_id] = asyncio.Future()
        try:
            yield self.callbacks[callback_id]
        finally:
            # Clean up callback on exit
            self.callbacks.pop(callback_id, None)


# Global server instance (singleton pattern)
_callback_server = CallbackServer()


async def _get_agent_response(agent, query: str) -> str:
    """Get response from agent using universal interface"""
    if callable(agent):
        return await agent(query) if asyncio.iscoroutinefunction(agent) else agent(query)
    elif hasattr(agent, "run"):
        return (
            await agent.run(query) if asyncio.iscoroutinefunction(agent.run) else agent.run(query)
        )
    else:
        raise ValueError("Agent must be callable or have .run() method")


async def ai(
    agent, query: str, llm=None, components: Optional[List[str]] = None, port: int = 8228
) -> AsyncGenerator[Dict, None]:
    """Transform any agent into UI-native interaction

    Agent generates response, shaper LLM selects optimal UI components,
    renderer creates interactive interface with bidirectional communication.
    """
    global _callback_server
    _callback_server.port = port

    # Only start server if we need interactive features (LLM provided)
    if llm:
        _callback_server.start_server()

    # Get agent response
    response = await _get_agent_response(agent, query)

    # Shape into components if LLM provided
    if llm:
        shaped = await shape(response, {"query": query, "components": components}, llm)
        try:
            component_array = json.loads(shaped)
            callback_id = str(uuid.uuid4())
            
            # Wrap component array in proper structure
            component_data = {
                "components": component_array,
                "callback_id": callback_id,
                "callback_url": f"http://localhost:{port}/callback/{callback_id}"
            }

            # Use context manager for clean callback handling
            async with _callback_server.callback_context(callback_id) as callback_future:
                yield {"type": "component", "data": component_data}

                # Wait for user interaction
                try:
                    user_event = await asyncio.wait_for(callback_future, timeout=300)
                    # Continue conversation with user selection
                    continuation = f"{query}\n\nUser selected: {user_event['data']}"
                    async for event in ai(agent, continuation, llm, components, port):
                        yield event
                except asyncio.TimeoutError:
                    logger.warning("User interaction timed out")
                    yield {"type": "text", "content": "Interaction timed out"}
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            yield {"type": "text", "content": response}
    else:
        yield {"type": "text", "content": response}


__all__ = ["ai", "protocol", "shape"]
